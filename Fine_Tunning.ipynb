{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "deba642dffc54050"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T15:07:50.909617Z",
     "start_time": "2025-11-18T15:07:50.899728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Torch Imports\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "import torch\n",
    "\n",
    "# Dataset Related\n",
    "import kagglehub\n",
    "\n",
    "# Plots and numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ],
   "id": "29d8214c37714a76",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Dataset\n",
    "In this repo I will use *Stanford Dogs Dataset* from kaggle\n",
    "https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset\n",
    "\n",
    "Originally from http://vision.stanford.edu/aditya86/ImageNetDogs/\n"
   ],
   "id": "586371c43fc80777"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Getting Data",
   "id": "295b9264497d4511"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T15:07:52.964923Z",
     "start_time": "2025-11-18T15:07:52.245987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download latest version\n",
    "DATA_PATH = kagglehub.dataset_download(\"jessicali9530/stanford-dogs-dataset\")\n",
    "IMG_PATH = os.path.join(DATA_PATH, \"images\", \"Images\")\n",
    "ANNOTATION_PATH = os.path.join(DATA_PATH, \"annotations\", \"Annotations\")\n",
    "\n",
    "print(\"Path to dataset files:\", DATA_PATH)"
   ],
   "id": "65d0c898f4f63eb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/franio/.cache/kagglehub/datasets/jessicali9530/stanford-dogs-dataset/versions/2\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T15:10:51.084368Z",
     "start_time": "2025-11-18T15:10:50.894205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = datasets.ImageFolder(root=IMG_PATH)\n",
    "dataset"
   ],
   "id": "c6d78c6cb76bc6c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 20580\n",
       "    Root location: /home/franio/.cache/kagglehub/datasets/jessicali9530/stanford-dogs-dataset/versions/2/images/Images"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Transforms\n",
    "\n",
    "Normalization is done with standard image net $\\mu$ and $\\sigma$"
   ],
   "id": "c64184304e68e814"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T15:07:54.979925Z",
     "start_time": "2025-11-18T15:07:54.976870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                        transforms.RandomHorizontalFlip(),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean, std)])\n",
    "\n",
    "test_transform = transforms.Compose([   transforms.Resize((224,224)),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean, std)])\n",
    "\n",
    "val_transform = transforms.Compose([transforms.Resize((224,224)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean, std)])"
   ],
   "id": "654829d953980f3a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train, Val and Test Split\n",
    "I assume that 10k images in total is enough for fine tuning. I will reconsider this value after testing a model. I will use 0.7/0.2/0.1 split\n"
   ],
   "id": "3a052b58cad0189f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T15:14:33.508671Z",
     "start_time": "2025-11-18T15:14:33.493802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "N = 1e4\n",
    "train_size = 0.7*N\n",
    "val_size = 0.2*N\n",
    "test_size = 0.1*N\n",
    "\n",
    "\n",
    "        if name in unfrozen_layers:\n",
    "\n",
    "\n"
   ],
   "id": "b5224ad984f0ad3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size:\t\t14406\n",
      "Testing set size:\t\t2058\n",
      "Validation set size:\t4116\n",
      "\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
